## OS 캐시와 분산

---

### 부하조정

- CPU: 비교적 간단함 (scale out + load balancer)
- I/O: DB 확장성을 확보하는 것이 쉽지 않은 일
  - write + 멀티 DB 시 데이터를 어떻게 동기화 할 것인가? (ex. A --> A`로 어떻게 가져올 것인가?)
  - 데이터가 커질수록 메모리에서 처리하지 못하고 디스크를 쓸 일이 많아지는데 메모리 <> 디스크 간의 속도 차이 때문에 이슈가 더 커진다.


### 대규모 데이터 다루기
1. 메모리에서 처리를 끝낼 수는 없을까?
- 디스크 seek 횟수 최소화
  - ex. warmup
    - OS 기동 직후에 서버를 투입하지 않고, 자주 사용하는 DB의 파일을 cat 해서 메모리에 올린 뒤 요청을 받도록 한다.
    - 운영상황에서는 캐시 또한 고려대상이므로 캐시가 최적화 된 후 부하테스트 등을 실시해야 한다.
- 국소성을 활용한 분산 실현
2. 데이터량 증가에 강한 알고리즘, 데이터 구조
- ex. O(N) --> O(log N)
3. 데이터 압축 (데이터량 감소를 통한 디스크 읽기 최소화), 혹은 검색기술


### I/O 부하 줄이기
- (무한정 늘릴 순 없지만) 메모리 증설
  - 메모리 캐싱을 활용한 I/O 축소
  - 비용과의 밸런스를 고려한 선택이 필요하다.
- scale out
  - DB 서버는 해당하지 않음
  - 단순히 대수를 늘이는 것이 해결책은 아님 
  - 캐싱할 수 없는 비율은 그대로 유지되기 때문이다. (복사된 서버에서 기존에 발생하던 문제가 동일하게 생기기 때문)


### 국소성(locality)을 고려한 분산
- 데이터에 대한 `액세스 패턴`을 고려해서 분산시키는 것 (= 효율적인 캐싱)
- 시스템 전반적으로 메모리에 올라간 데이터량이 늘어나게 된다. 
<br>
<br>


#### 파티셔닝
- DB 서버를 여러 대의 서버로 분할하는 방법
  - 테이블 단위의 분할 (ex. 테이블 A, B는 데이터베이스1, C, D는 데이터베이스2 ...)
  - 테이블 데이터 분할 (ex. 한 테이블에서 row 1, 2, 3은 데이터베이스1, 4, 5, 6은 데이터베이스2 ...)


#### 요청패턴을 '섬'으로 분할
- 여기서 말하는 섬은 예시 그림을 보면 `클러스터`를 의미하는 듯 (DB서버의 집합)
- 핵심은 캐싱하기 쉬운 요청과 캐싱하기 어려운 요청을 구분하라는 것
  - 캐싱하기 어려운 요청의 예시: Crawling Bot
  - 응답시간이 사실 상관없었지만 구글에서 응답시간 또한 검색순위에 반영하도록 업데이트 했다고 한다.


#### 용도특화형 인덱싱
- RDBMS: `범용적`인 용도로 만들어진 프로그램
  - 특정한 목적으로만 사용하고자 할 때, 특정한 목적만으로 사용할 수 있도록 튜닝한 데이터구조를 사용
- = 용도특화형 인덱싱
  - ex. 검색에서의 역인덱스


## 알고리즘의 실용화

---

### 패턴매칭 
- Regex
  - 정규표현식의 패턴매칭 구현에는 오토마톤(automaton) 이 활용됨 (그 중에서도 NFA: Nondeterministic Finite Automata)
  - 앞에서부터 하나씩 입력값을 살펴가면서 매칭
    - ex. (foo|bar|baz): foo 매칭확인, bar 매칭확인, baz 매칭확인
    - 키워드의 개수에 비례하는 계산량
- Trie
  - 트라이 생성 후 매칭여부 확인
  - `단어의 길이`만큼만 매칭여부를 확인하면 된다. 
  - `AC(Aho-Corasic)법`
    - 사전 내에서 패턴매칭을 수행하는 오토마톤을 구축하고 입력 텍스트에 대해 선형 계산시간 실현 (계산량이 사전크기에 의존하지 않는 빠른방법)
    - ![ac_trie.png](img%2Fac_trie.png)
- Regexp::List
  - Trie 기반의 정규표현 생성 (= Trie에 의해 최적화된 정규표현으로 변환)

**knowhow)** 
1. 최적의 구현을 사용하는 것이 반드시 옳은 것은 아니다. (데이터가 작다면 간단한 구현이 - 시간대비 효용성을 생각했을 때 - 결과가 좋을 수도 있다.)
2. 데이터가 대규모가 될 시기를 대비해서 본질적인 문제의 해결방법을 찾아두어야 한다.


## 전문검색

---

예시: `키워드`를 포함하는 블로그 찾기

### RDB로 처리하기
- 해당 글에 포함되어 있는 키워드를 전부 추출
- 확장성 측면에서의 문제점 (확인해야 할 레코드가 너무 많아짐)

### 검색엔진 구현하기
- 데이터베이스 측면에서의 한계를 극복하기 위한 방법

<br>

**검색시스템의 아키텍쳐**
1. 크롤링: 검색할 대상 문서를 가져온다.
2. 저장
3. 인덱싱: 가져온 문서에 대한 인덱스를 구축한다.
4. 검색
5. 스코어링: 검색결과를 어떤 순서로 표시해줄 것인가?
6. 결과표시

<br>

**전문검색의 종류**
- grep형
  - 처음부터 전부 읽어가기
  - 장점
    - simplest
    - 즉시성: 문서가 갱신되더라도 바로 검색가능
    - 전부 읽으므로 검색누락이 발생하지 않음
    - 병렬화가 간단 (ex. 분할 후 병렬검색, 검색하고자 하는 단어를 하나의 오토마톤에 모아서 그 안으로 문서를 집어넣게 되면 복수 검색어를 한 번에 검색할 수 있음)
  - 단점
    - O(mn): 텍스트의 길이를 m, 검색하려는 검색어의 길이를 n이라고 했을 때 걸리는 시간
      - KMP(Knuth-Morris-Pratt)법, BM(Boyer-Moore)법 등 어느정도 계산량을 개선한 방법이 있지만, 어쨌든 처음부터 모든 문서를 읽어가므로 데이터가 늘어나면 효용성이 떨어진다.
- suffix형
  - 검색대상 전문을 검색가능한 형태로 가지고 있음 (ex. Trie, Suffix Array, Suffix Tree 등)
  - 전문을 위의 데이터 구조로 변환한 후 메모리에 올려 검색속도를 올리는 방식
  - 문제점 
    - 이론적으로는 가능하나, 정보량이 크고 구현이 어렵다.
- 역 인덱스형 (Inverted Index)
  - 단어(term)와 문서를 연관짓는 것
  - 역 인덱스를 문서와는 별개로 만들어야 한다. (= 검색 전 인덱스 전처리)
  - 장점
    - 인덱스를 압축함으로써 컴팩트하게 가져갈 수 있다.
    - 밸런스 좋은 아키텍쳐 (대규모화하기 나름 편리하고, 구현 공수도 적절하다고 함)
  - 단점 (grep형의 장점이 여기로)
    - 전처리가 필요하므로 즉시 검색결과가 반영되는 형태의 구현은 불가능하다.
    - 검색 누락이 발생할 수도 있다.